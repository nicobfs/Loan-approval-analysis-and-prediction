{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMPBvHMfFujlTrivTu0V9EA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicobfs/Loan-approval-analysis-and-prediction/blob/main/Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name : Nico Berlinson Fernando </br>\n",
        "Email : nicobfs1@gmail.com </br>\n"
      ],
      "metadata": {
        "id": "dz1tWauKvSVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_i9ucqz5ntJ"
      },
      "outputs": [],
      "source": [
        "# Checking version TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "metadata": {
        "id": "1MDvM3NtA7Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split_folders"
      ],
      "metadata": {
        "id": "pskLiPxwBtvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and downloading dataset\n",
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \\\n",
        "  -O /tmp/rockpaperscissors.zip"
      ],
      "metadata": {
        "id": "dXPh6bhD5wVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the zip file\n",
        "import zipfile,os\n",
        "local_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        " "
      ],
      "metadata": {
        "id": "C70q-g3v6MDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/tmp/rockpaperscissors')\n"
      ],
      "metadata": {
        "id": "-86BELsg6vPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defines directory names for training data and validation data.\n",
        "import splitfolders\n",
        "\n",
        "base_dir = '/tmp/rockpaperscissors/rps-cv-images'\n",
        "splitfolders.ratio(base_dir, output = \"/tmp/rockpaperscissors\", seed  = 1337, ratio = (.6, .4))\n",
        "\n",
        "train_dir = os.path.join(\"/tmp/rockpaperscissors\", 'train')\n",
        "validation_dir = os.path.join(\"/tmp/rockpaperscissors\", 'val')\n"
      ],
      "metadata": {
        "id": "Ov0Wi-bQDWgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rock_dir = os.path.join(base_dir, 'rock')\n",
        "paper_dir = os.path.join(base_dir, 'paper')\n",
        "scissors_dir = os.path.join(base_dir, 'scissors')"
      ],
      "metadata": {
        "id": "80JtuF1tHT_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# breaks the rock directory into data train and data validation\n",
        "train_rock_dir, val_rock_dir = train_test_split (os.listdir (rock_dir), test_size = 0.4, train_size=0.6)\n",
        "\n",
        "# break the paper directory into data train and data validation\n",
        "train_paper_dir, val_paper_dir = train_test_split (os.listdir (paper_dir), test_size = 0.4, train_size=0.6)\n",
        "\n",
        "# break the scissors directory into data train and data validation\n",
        "train_scissors_dir, val_scissors_dir = train_test_split (os.listdir (scissors_dir), test_size = 0.4, train_size=0.6)\n"
      ],
      "metadata": {
        "id": "FqCjHPTKHuUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rock = os.path.join (train_dir, 'rock')\n",
        "train_paper = os.path.join (train_dir, 'paper')\n",
        "train_scissors = os.path.join (train_dir, 'scissors')\n",
        "\n",
        "val_rock = os.path.join (validation_dir, 'rock')\n",
        "val_paper = os.path.join (validation_dir, 'paper')\n",
        "val_scissors = os.path.join (validation_dir, 'scissors')"
      ],
      "metadata": {
        "id": "xeJTRcgBIaS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image augmentation process on each sample in the dataset\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "#prepare training and validation data from image dataset loaded in memory\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                    train_dir,\n",
        "                    target_size=(150,150),\n",
        "                    batch_size = 32,\n",
        "                    class_mode = 'categorical'\n",
        ")\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "                    validation_dir,\n",
        "                    target_size=(150,150),\n",
        "                    batch_size = 32,\n",
        "                    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "llR8qJAm63Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make models\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Q7zhjdhdJ4C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see a summary of the model architecture that has been made\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "O_IvbyGnKLeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model with 'adam' optimizer loss function 'categorical_crossentropy'\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DnGjzwIIKQsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train models with model.fit\n",
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=25, # how many batches will be executed in each epoch\n",
        "      epochs=20,\n",
        "      validation_data=test_generator, # displays the accuracy of validation data testing\n",
        "      validation_steps=5,  # how many batches will be executed in each epoch\n",
        "      verbose=2)"
      ],
      "metadata": {
        "id": "uC_tCfNbfuS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)  \n",
        "  print(fn)\n",
        "  if classes[0][0]==1:\n",
        "    print('Paper')\n",
        "  elif classes[0][1]==1:\n",
        "    print('Rock')\n",
        "  elif classes[0][2]==1:\n",
        "   print('Scissors')"
      ],
      "metadata": {
        "id": "vBASSzLef9pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)  \n",
        "  print(fn)\n",
        "  if classes[0][0]==1:\n",
        "    print('Paper')\n",
        "  elif classes[0][1]==1:\n",
        "    print('Rock')\n",
        "  elif classes[0][2]==1:\n",
        "   print('Scissors')"
      ],
      "metadata": {
        "id": "ikb6LVTXoA_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)  \n",
        "  print(fn)\n",
        "  if classes[0][0]==1:\n",
        "    print('Paper')\n",
        "  elif classes[0][1]==1:\n",
        "    print('Rock')\n",
        "  elif classes[0][2]==1:\n",
        "   print('Scissors')"
      ],
      "metadata": {
        "id": "6TqN48VhvDf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xLagO8ei7YqZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}